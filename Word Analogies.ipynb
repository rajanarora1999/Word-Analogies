{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import reqd libraries\n",
    "#Gensim contains the word2vec model\n",
    "#Word2Vec is a pre trained model from google which contains a 300 sized vector for each of the 50 billion words\n",
    "from gensim.models import word2vec,KeyedVectors\n",
    "#Cosine similarity is used to calculate the similarity between two words(it is 1 for same words)\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we load the dataset which contains word vectors of 50 billion words\n",
    "#GoogleNews-vectors-negative300.bin is the dataset file\n",
    "word_vectors=KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin',binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example of Analogy man:woman :: king:?\n",
    "#now answer should be queen\n",
    "#now we see that similarity difference between  man and woman hsould be nearly equal to similarity difference between king and queen\n",
    "#i.e a:b::c:d then a-b=c-d -> d=c+b-a\n",
    "#we convert each word into vector and then using d=c+b-a we calculate the analogous vector\n",
    "#then we iterate over all the words and see that which vector is the most similar to our analogous vector\n",
    "#similarity is checked using cosine similarity\n",
    "def FindAnalogies(a,b,c):\n",
    "    a,b,c=a.lower(),b.lower(),c.lower()\n",
    "    analogous_vector=word_vectors[b]-word_vectors[a]+word_vectors[c]\n",
    "    max_sim=-1.0\n",
    "    Analogous_word=None\n",
    "    words=word_vectors.vocab.keys()\n",
    "    for w in words:\n",
    "        if w in [a,b,c]:\n",
    "            continue\n",
    "        sim=cosine_similarity([word_vectors[w]],[analogous_vector])\n",
    "        if sim >=max_sim:\n",
    "            max_sim=sim\n",
    "            Analogous_word=w\n",
    "    return Analogous_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'queen'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FindAnalogies('man','woman','king')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7118192911148071)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#direct way of implementing word analogy . give the ones to be added to positive \n",
    "#the ones to be subtracted to negative\n",
    "#topn is the number of similar words reqd\n",
    "word_vectors.most_similar(positive=['king','woman'],negative=['man'],topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
